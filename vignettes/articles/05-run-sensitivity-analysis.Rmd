---
title: "04 - Start a local MLFlow server and use it to track independant TRISK runs"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Installing MLFlow and booting the server

1. Install conda from https://docs.conda.io/en/latest/miniconda.html or use another python package manager to complete the next steps.
2. Create a new environment with python 3.10 : 

```{bash, eval = FALSE}
conda create -n mlflow_env python=3.10
```

3. Activate the environment and install MLFlow via pip :

```{bash, eval = FALSE}
conda activate mlflow_env
pip install mlflow
```

4. Open a terminal in the TRISK repository folder and re-activate the conda environment if it is not activated already. The mlflow server can the be started using the following command. Replace the PROJECT_NAME accordingly with the name of the folder where mlflow should read/write the runs outputs.
```{bash, eval = FALSE}
mlflow server --backend-store-uri PROJECT_NAME/mlruns --default-artifact-root PROJECT_NAME/mlartifacts --host 127.0.0.1 --port 5000 --serve-artifacts
```

5. Connect to the server UI by entering this adress in a web browser : 

```
http://localhost:5000
```

# Starting an experiment and recording runs

1. To use mlflow with R, the environment variables MLFLOW_PYTHON_BIN and MLFLOW_BIN must be configured. On a MAC, the values for those variables can be obtained by typing `where python` and `where mlflow` in a terminal with the conda environment activated. They usually look like this : 

```{bash, eval = FALSE}
% where python
/Users/username/opt/miniconda3/envs/mlflow_env/bin/python
% where mlflow
/Users/username/opt/miniconda3/envs/mlflow_env/bin/mlflow
```

2. Set those environment variables in R using this command in the R console :

```{r, eval = FALSE}
Sys.setenv(
MLFLOW_PYTHON_BIN = "mlflow_python_bin/Users/username/opt/miniconda3/envs/mlflow_env/bin/python",
MLFLOW_BIN = "/Users/username/opt/miniconda3/envs/mlflow_env/bin/mlflow"
)
```

3. Run an experiment on different values of a set of parameters, using the function `multirun_trisk_mlflow()`. 
- For each line of the scenario_pairs tibble, all parameters will be used once in a run. 
- Change the value of experiment_name to record a new set of run in a separate directory in the mlflow output folders, or leave it the same to append new runs to an existing experiment. 
- Saving TRISK outputs for each run can quickly take up storage space (300Mo per run). To ignore the saving of the outputs and only record the metrics/tags of each run, set save_artifacts to FALSE.

Example syntax for `multirun_trisk_mlflow()`:
```{r, eval = FALSE}

  scenario_pairs = tibble::tribble(
    ~baseline_scenario, ~shock_scenario,
    "WEO2021_STEPS", "WEO2021_SDS",
    "WEO2021_APS", "WEO2021_NZE_2050"
  )
  params_grid = list(
    discount_rate = c(0.015, 0.04, 0.07, 0.1),
    lgd = c(0.3, 0.45, 0.6, 0.75, 0.9),
    risk_free_rate = c(0, 0.02, 0.05),
    growth_rate = c(0.01, 0.03, 0.099),
    div_netprofit_prop_coef = c(0.8, 0.85, 0.9, 0.95, 1),
    shock_year = c(2025, 2027, 2029, 2030, 2032, 2034, 2035),
    scenario_geography = c("Global"),
    #settlement_factor = c(0, 0.3, 0.6, 1),
    #exp_share_damages_paid = c(0, 0.027, 0.1, 0.5, 1),
    #scc = c(0, 40, 400, 4000, 10000),
    #carbon_price_model = c("no_carbon_tax", "NZ2050", "NDC", "DN0", "B2DS"),
    market_passthrough = c(0, 0.3, 0.6, 1)
  )


  multirun_trisk_mlflow(
    tracking_uri = "http://127.0.0.1:5000",
    experiment_name = "EXPERIMENT_NAME",
    trisk_input_path = "example_project/project_input",
    trisk_output_path = "example_project/output",
    scenario_pairs = scenario_pairs,
    params_grid = params_grid,
    save_artifacts=TRUE
  )

```

# Searching runs and extracting their outputs

1. The run details can be obtained this way, by specifying a filter. Examples syntax of the filter can be found here : https://mlflow.org/docs/latest/search-runs.html .

The tags currently recorded are the parameter name being tweaked for this run (T/F), and the final LOG_STATUS of the run in case it fails (SUCCESS/FAILED).

```{r, eval = FALSE}
mlflow::mlflow_set_tracking_uri(uri = "127.0.0.1:5000")
mlflow::mlflow_client()
experiment <- mlflow::mlflow_get_experiment(name = "EXPERIMENT_NAME")
experiment_id <- experiment[[1, "experiment_id"]]

# will return a tibble containing the metadatas of all runs 
# where the parameter shock_year has been tweaked.
runs <- mlflow::mlflow_search_runs(
  filter = "tags.shock_year = 'TRUE'",
  experiment_ids = as.character(experiment_id)
  )
```

2. After obtaining a run_id with the previous commands, the artifacts saved during this run can be obtained this way. Where `artifact_name` is one of company_trajectories_.csv, crispy_output_.csv, time_spent.csv . If a run fails, the only available artifact is the error message returned by the `run_trisk()` function.

```{r, eval = FALSE}
mlflow::mlflow_set_tracking_uri(uri = tracking_uri)
mlflow::mlflow_client()
# path refers to the folder inside a run where the artifacts are saved.
# in this case, all artifacts are saved at the root of each run.
artifacts_path <- mlflow::mlflow_download_artifacts(path="", run_id = run_id)
artifact <- readr::read_csv(file.path(artifacts_path, artifact_name), show_col_types = FALSE)
```

